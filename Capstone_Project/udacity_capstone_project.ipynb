{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Deep dive\n",
    "The Capstone project utilises immigration data from the International Trade Administration (ITA) and World Temperature Data from a dataset from kaggle. \\\n",
    "The main purpose of this project is to explore data, create an efficient database with an optimised data model, and allow users to validate initial hypotheses surrounding the seasonality of immigration. The data used is not complete enough to provide conclusive insights into the correlation between temperature and immigration due to the immigration data only being available for 2016. The temperature data only goes until 2013. We can however extrapolate the average temperatures and apply them to our analysis. \n",
    " \n",
    "The sort of questions that users may want to answer are as follows:\n",
    "- Does temperature have an effect on immigration fluxes?\n",
    "- Are immigration fluxes prone to seasonality?\n",
    "- Are higher temperatures repellent for immigration? \n",
    "- Do higher temperatures constitute for dangerous situations surrounding immigration movements?\n",
    "- Which months do immigrants enter the USA most frequently?\n",
    "- Do we experience significant amplitude in immigration over different years and months?\n",
    "- Which cities do immigrants enter the most?\n",
    "\n",
    "As stated, to answer all of these questions more data is needed, but the model and functions are set up in a such a way that this data can easily be added to fully enrich the database. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import count, isnan\n",
    "pd.set_option('display.max_rows', 50, 'display.max_columns', 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_sub = pd.read_csv('immigration_data_sample.csv')\n",
    "# reading the whole immigration dataset using pandas was not feasible so initially the sample file is used\n",
    "us_cities = pd.read_csv(\"us-cities-demographics.csv\", sep = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "tempa_file_name = \"GlobalLandTemperaturesByCity.csv\"\n",
    "tempa = pd.read_csv(tempa_file_name, sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern = re.compile(r\"\\'(.*)\\'.*\\'([A-Z\\-a-z]+)(.*)\\'\")\n",
    "i94_ports = {}\n",
    "cities = {}\n",
    "with open(\"I94_SAS_Labels_Descriptions.sas\") as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines[303:962]:\n",
    "    match = regex_pattern.search(line)\n",
    "    i94_ports[match[1]] = match[2]\n",
    "    cities[match[2].title()] = match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anchorage': 'ANC',\n",
       " 'Baker': 'BAR',\n",
       " 'Daltons': 'DAC',\n",
       " 'Dew': 'PIZ',\n",
       " 'Dutch': 'DTH',\n",
       " 'Eagle': 'EGP',\n",
       " 'Fairbanks': 'FRB',\n",
       " 'Homer': 'HOM',\n",
       " 'Hyder': 'HYD',\n",
       " 'Juneau': 'JUN',\n",
       " 'Ketchikan': 'KET',\n",
       " 'Moses': 'MWH',\n",
       " 'Nikiski': 'NIK',\n",
       " 'Nom': 'NOM',\n",
       " 'Poker': 'PKC',\n",
       " 'Port': 'PTO',\n",
       " 'Skagway': 'SKA',\n",
       " 'St': 'STA',\n",
       " 'Tokeen': 'TKI',\n",
       " 'Wrangell': 'WRA',\n",
       " 'Madison': 'HSV',\n",
       " 'Mobile': 'MOB',\n",
       " 'Little': 'LIA',\n",
       " 'Rogers': 'ROG',\n",
       " 'Douglas': 'DOU',\n",
       " 'Lukeville': 'LUK',\n",
       " 'Mariposa': 'MAP',\n",
       " 'Naco': 'NAC',\n",
       " 'Nogales': 'NOG',\n",
       " 'Phoenix': 'PHO',\n",
       " 'Portal': 'POR',\n",
       " 'San': 'SAN',\n",
       " 'Sasabe': 'SAS',\n",
       " 'Tucson': 'TUC',\n",
       " 'Yuma': 'YUM',\n",
       " 'Andrade': 'AND',\n",
       " 'Burbank': 'BUR',\n",
       " 'Calexico': 'CAL',\n",
       " 'Campo': 'CAO',\n",
       " 'Fresno': 'FRE',\n",
       " 'Imperial': 'ICP',\n",
       " 'Long': 'LNB',\n",
       " 'Los': 'LOI',\n",
       " 'Meadows': 'BFL',\n",
       " 'Oakland': 'PTK',\n",
       " 'Ontario': 'ONT',\n",
       " 'Otay': 'OTM',\n",
       " 'Pacific': 'BLT',\n",
       " 'Palm': 'PSP',\n",
       " 'Sacramento': 'SAC',\n",
       " 'Salinas': 'SLS',\n",
       " 'Santa': 'STR',\n",
       " 'Stockton': 'STO',\n",
       " 'Tecate': 'TEC',\n",
       " 'Travis-Afb': 'TRV',\n",
       " 'Arapahoe': 'APA',\n",
       " 'Aspen': 'ASE',\n",
       " 'Colorado': 'COS',\n",
       " 'Denver': 'DEN',\n",
       " 'La': 'LAG',\n",
       " 'Bradley': 'BDL',\n",
       " 'Bridgeport': 'BGC',\n",
       " 'Groton': 'GRT',\n",
       " 'Hartford': 'HAR',\n",
       " 'New': 'NYC',\n",
       " 'Newington': 'TST',\n",
       " 'Washington': 'WAS',\n",
       " 'Dover': 'DOV',\n",
       " 'Dover-Afb': 'DVD',\n",
       " 'Wilmington': 'WIL',\n",
       " 'Bocagrande': 'BOC',\n",
       " 'Bradenton': 'SRQ',\n",
       " 'Cape': 'CAP',\n",
       " 'Daytona': 'DAB',\n",
       " 'Fernandina': 'FRN',\n",
       " 'Fort': 'AFW',\n",
       " 'Hurlburt': 'HUR',\n",
       " 'J': 'GNV',\n",
       " 'Jacksonville': 'JAC',\n",
       " 'Key': 'KEY',\n",
       " 'Leesburg': 'LEE',\n",
       " 'Melbourne': 'MLB',\n",
       " 'Miami': 'MIA',\n",
       " 'Naples': 'APF',\n",
       " 'Opa': 'OPF',\n",
       " 'Orlando': 'ORL',\n",
       " 'Panama': 'PAN',\n",
       " 'Pensacola': 'PEN',\n",
       " 'Sanford': 'SFB',\n",
       " 'Tampa': 'TAM',\n",
       " 'West': 'LGW',\n",
       " 'Atlanta': 'ATL',\n",
       " 'Brunswick': 'BRU',\n",
       " 'Bush': 'AGS',\n",
       " 'Savannah': 'SAV',\n",
       " 'Agana': 'AGA',\n",
       " 'Honolulu': 'HHW',\n",
       " 'Kahului': 'OGG',\n",
       " 'Keahole-Kona': 'KOA',\n",
       " 'Lihue': 'LIH',\n",
       " 'Cedar': 'CID',\n",
       " 'Des': 'DSM',\n",
       " 'Air': 'BOI',\n",
       " 'Eastport': 'EPM',\n",
       " 'Fanning': 'IDA',\n",
       " 'Porthill': 'PTL',\n",
       " 'Capital': 'SPI',\n",
       " 'Chicago': 'CHI',\n",
       " 'Dupage': 'DPA',\n",
       " 'Greater': 'RFD',\n",
       " 'Memorial': 'UGN',\n",
       " 'Gary': 'GAR',\n",
       " 'Hammond': 'HMM',\n",
       " 'Indianapolis': 'INP',\n",
       " 'Merrillville': 'MRL',\n",
       " 'South': 'SBR',\n",
       " 'Mid-Continent': 'ICT',\n",
       " 'Blue': 'LEX',\n",
       " 'Louisville': 'LOU',\n",
       " 'Baton': 'BTN',\n",
       " 'Lake': 'LAK',\n",
       " 'Monroe': 'MLU',\n",
       " 'Morgan': 'MGM',\n",
       " 'Boston': 'BOS',\n",
       " 'Gloucester': 'GLO',\n",
       " 'Hanscom': 'BED',\n",
       " 'Lynden': 'LYN',\n",
       " 'Andrews': 'ADW',\n",
       " 'Baltimore': 'BAL',\n",
       " 'Muskegon': 'MKG',\n",
       " 'Patuxent': 'PAX',\n",
       " 'Bangor': 'BGM',\n",
       " 'Boothbay': 'BOO',\n",
       " 'Bridgewater': 'BWM',\n",
       " 'Buckport': 'BCK',\n",
       " 'Calais': 'CLS',\n",
       " 'Caribou': 'CAR',\n",
       " 'Coburn': 'COB',\n",
       " 'Eastcourt': 'EST',\n",
       " 'Forest': 'FOR',\n",
       " 'Hamiin': 'HML',\n",
       " 'Houlton': 'HTM',\n",
       " 'Jackman': 'JKM',\n",
       " 'Kalispel': 'KAL',\n",
       " 'Limestone': 'LIM',\n",
       " 'Lubec': 'LUB',\n",
       " 'Madawaska': 'MAD',\n",
       " 'Portland': 'POO',\n",
       " 'Rangeley': 'RGM',\n",
       " 'Van': 'VNY',\n",
       " 'Vanceboro': 'VCB',\n",
       " 'Algonac': 'AGN',\n",
       " 'Alpena': 'ALP',\n",
       " 'Bay': 'BCY',\n",
       " 'Detroit': 'DET',\n",
       " 'Grand': 'GCM',\n",
       " 'Grosse': 'GRO',\n",
       " 'Isle': 'ISL',\n",
       " 'Marine': 'MRC',\n",
       " 'Marysville': 'MRY',\n",
       " 'Roberts': 'RDM',\n",
       " 'Saginaw': 'SAG',\n",
       " 'Sault': 'SSM',\n",
       " 'Willow': 'WCM',\n",
       " 'Baudette': 'BAU',\n",
       " 'Collapsed': 'T01',\n",
       " 'Crane': 'CDD',\n",
       " 'Crystal': 'MIC',\n",
       " 'Duluth': 'DUL',\n",
       " 'Ely': 'ELY',\n",
       " 'Grant': 'SVC',\n",
       " 'L': \"INT'\\t=\\t'INT\",\n",
       " 'Lancaster': 'LAN',\n",
       " 'Minn': 'MSP',\n",
       " 'Northern': 'LIN',\n",
       " 'Noyes': 'NOY',\n",
       " 'Pine': 'PIN',\n",
       " 'Pinecreek': '48Y',\n",
       " 'Rainer': 'RAN',\n",
       " 'Rochester': 'ROC',\n",
       " 'Roseau': 'ROS',\n",
       " 'Warroad': 'WAR',\n",
       " 'Kansas': 'KAN',\n",
       " 'Springfield-Branson': 'SGF',\n",
       " 'Whitetail': 'WHI',\n",
       " 'Wild': 'WHM',\n",
       " 'Biloxi': 'GPT',\n",
       " 'Golden': 'GTR',\n",
       " 'Gulfport': 'GUL',\n",
       " 'Pascagoula': 'PAS',\n",
       " 'Thompson': 'JAN',\n",
       " 'Billings': 'BIL',\n",
       " 'Butte': 'BTM',\n",
       " 'Chief': 'CHF',\n",
       " 'Cut': 'CUT',\n",
       " 'Del': 'DLR',\n",
       " 'Eureka': 'EUR',\n",
       " 'Gallatin': 'BZN',\n",
       " 'Glacier': 'FCA',\n",
       " 'Glasgow': 'GGW',\n",
       " 'Great': 'GRE',\n",
       " 'Havre': 'HVR',\n",
       " 'Helena': 'HEL',\n",
       " 'Lewiston': 'LEW',\n",
       " 'Opheim': 'OPH',\n",
       " 'Piegan': 'PIE',\n",
       " 'Raymond': 'RAY',\n",
       " 'Roosville': 'ROO',\n",
       " 'Scobey': 'SCO',\n",
       " 'Sweetgtass': 'SWE',\n",
       " 'Trial': 'TRL',\n",
       " 'Turner': 'TUR',\n",
       " 'Charlotte': 'CHA',\n",
       " 'Fayetteville': 'FAY',\n",
       " 'Morehead': 'MRH',\n",
       " 'Morris': 'FOP',\n",
       " 'Piedmont': 'GSO',\n",
       " 'Raleigh': 'RDU',\n",
       " 'Shaw': 'SSC',\n",
       " 'Ambrose': 'AMB',\n",
       " 'Antler': 'ANT',\n",
       " 'Carbury': 'CRY',\n",
       " 'Dunseith': 'DNS',\n",
       " 'Fargo': 'FAR',\n",
       " 'Fortuna': 'FRT',\n",
       " 'Hannah': 'HNN',\n",
       " 'Hansboro': 'HNS',\n",
       " 'Maida': 'MAI',\n",
       " 'Minot': 'MND',\n",
       " 'Neche': 'NEC',\n",
       " 'Noonan': 'NOO',\n",
       " 'Northgate': 'NRG',\n",
       " 'Pembina': 'PEM',\n",
       " 'Sarles': 'SAR',\n",
       " 'Sherwood': 'SHR',\n",
       " 'Walhalla': 'WAL',\n",
       " 'Westhope': 'WHO',\n",
       " 'Williston': 'WND',\n",
       " 'Omaha': 'OMA',\n",
       " 'Lebanon': 'LEB',\n",
       " 'Manchester': 'MHT',\n",
       " 'Pittsburg': 'PIT',\n",
       " 'Portsmouth': 'PSM',\n",
       " 'Bayonne': 'BYO',\n",
       " 'Camden': 'CNJ',\n",
       " 'Hoboken': 'HOB',\n",
       " 'Jersey': 'JER',\n",
       " 'Mc': 'TYS',\n",
       " 'Morristown': 'MRR',\n",
       " 'Newark': 'NEW',\n",
       " 'Perth': 'PER',\n",
       " 'Pomona': 'ACY',\n",
       " 'Alamagordo': 'ALA',\n",
       " 'Albuquerque': 'ABQ',\n",
       " 'Antelope': 'ANP',\n",
       " 'Carlsbad': 'CRL',\n",
       " 'Columbus': 'CLM',\n",
       " 'Deming': 'DNM',\n",
       " 'Las': 'LVG',\n",
       " 'Lordsburg': 'LOB',\n",
       " 'Ruidoso': 'RUI',\n",
       " 'Cannon': 'CNC',\n",
       " 'Fallon': 'FLX',\n",
       " 'Reno': 'REN',\n",
       " 'Albany': 'ALB',\n",
       " 'Alexandria': 'AXB',\n",
       " 'Buffalo': 'BUF',\n",
       " 'Champlain': 'CHM',\n",
       " 'Chateaugay': 'CHT',\n",
       " 'Clayton': 'CLA',\n",
       " 'Massena': 'MAS',\n",
       " 'Mcguire': 'MAG',\n",
       " 'Moores': 'MOO',\n",
       " 'Niagara': 'NIA',\n",
       " 'Ogdensburg': 'OGD',\n",
       " 'Oswego': 'OSW',\n",
       " 'Regional': 'ELM',\n",
       " 'Rouses': 'ROU',\n",
       " 'Stewart': 'SWF',\n",
       " 'Syracuse': 'SYR',\n",
       " 'Thousand': 'THO',\n",
       " 'Trout': 'TRO',\n",
       " 'Watertown': 'WAT',\n",
       " 'Westchester': 'HPN',\n",
       " 'Whirlpool': 'WRB',\n",
       " 'Youngstown': 'YOU',\n",
       " 'Akron': 'CAK',\n",
       " 'Ashtabula': 'ATB',\n",
       " 'Cincinnati': 'CIN',\n",
       " 'Cleveland': 'CLE',\n",
       " 'Lorain': 'LOR',\n",
       " 'Marble': 'MBO',\n",
       " 'Sandusky': 'SDY',\n",
       " 'Toledo': 'TOL',\n",
       " 'Oklahoma': 'OKC',\n",
       " 'Tulsa': 'TUL',\n",
       " 'Astoria': 'AST',\n",
       " 'Coos': 'COO',\n",
       " 'Hillsboro': 'HIO',\n",
       " 'Medford': 'MED',\n",
       " 'Newport': 'NPV',\n",
       " 'Put-In-Bay': 'PUT',\n",
       " 'Erie': 'ERI',\n",
       " 'Harrisburg': 'MDT',\n",
       " 'Harrisonburg': 'HSB',\n",
       " 'Philadelphia': 'PHI',\n",
       " 'Aguadilla': 'AGU',\n",
       " 'Borinquen': 'BQN',\n",
       " 'Culebra': 'JCP',\n",
       " 'Ensenada': 'ENS',\n",
       " 'Fajardo': 'FAJ',\n",
       " 'Humacao': 'HUM',\n",
       " 'Jobos': 'JOB',\n",
       " 'Mayaguez': 'MAY',\n",
       " 'Ponce': 'PON',\n",
       " 'Ponce-Mercedita': 'PSE',\n",
       " 'Vieques-Arpt': 'VQS',\n",
       " 'Providence': 'PRO',\n",
       " 'Theodore': 'PVD',\n",
       " 'Charleston': 'CHS',\n",
       " 'Columbia': 'CAE',\n",
       " 'Georgetown': 'GEO',\n",
       " 'Greenville': 'GSP',\n",
       " 'Greer': 'GRR',\n",
       " 'Myrtle': 'MYR',\n",
       " 'Black': 'SPF',\n",
       " 'Howes': 'HON',\n",
       " 'Saipan': 'SAI',\n",
       " 'Memphis': 'MEM',\n",
       " 'Nashville': 'NSV',\n",
       " 'Tri': 'TRI',\n",
       " 'Addison': 'ADS',\n",
       " 'Amistad': 'ADT',\n",
       " 'Anzalduas': 'ANZ',\n",
       " 'Austin': 'AUS',\n",
       " 'Beaumont': 'BEA',\n",
       " 'Big': 'BBP',\n",
       " 'Bp': 'BTC',\n",
       " 'Bridge': 'BOA',\n",
       " 'Brownsville': 'BRO',\n",
       " 'Corpus': 'CRP',\n",
       " 'Dallas': 'DAL',\n",
       " 'Donna': 'DNA',\n",
       " 'El': 'ELP',\n",
       " 'Fabens': 'FAB',\n",
       " 'Falcon': 'FAL',\n",
       " 'Freeport': 'FBA',\n",
       " 'Galveston': 'GAL',\n",
       " 'Harlingen': 'HLG',\n",
       " 'Hidalgo': 'HID',\n",
       " 'Houston': 'HOU',\n",
       " 'Hull': 'SGR',\n",
       " 'Juarez-Lincoln': 'LLB',\n",
       " 'Laredo': 'LAR',\n",
       " 'Marfa': 'MAR',\n",
       " 'Mcallen': 'MCA',\n",
       " 'Odessa': 'MAF',\n",
       " 'Paso': 'PDN',\n",
       " 'Peace': 'PBB',\n",
       " 'Pharr': 'PHR',\n",
       " 'Presidio': 'PRE',\n",
       " 'Progreso': 'PGR',\n",
       " 'Rio': 'RIO',\n",
       " 'Roma': 'ROM',\n",
       " 'Sanderson': 'SNN',\n",
       " 'Veteran': 'VIB',\n",
       " 'Ysleta': 'YSL',\n",
       " 'Christiansted': 'CHR',\n",
       " 'Cruz': 'CRU',\n",
       " 'Frederiksted': 'FRK',\n",
       " 'Cache': 'LGU',\n",
       " 'Salt': 'SLC',\n",
       " 'Albemarle': 'CHO',\n",
       " 'Davison': 'DAA',\n",
       " 'Hopewell': 'HOP',\n",
       " 'Manassas': 'HEF',\n",
       " 'Norfolk': 'NOR',\n",
       " 'Richmond': 'RCM',\n",
       " 'Alburg': 'ABG',\n",
       " 'Beebe': 'BEB',\n",
       " 'Beecher': 'BEE',\n",
       " 'Burlington': 'BRG',\n",
       " 'Canaan': 'CNA',\n",
       " 'Derby': 'DLV',\n",
       " 'East': 'ERC',\n",
       " 'Highgate': 'HIG',\n",
       " 'Morses': 'MOR',\n",
       " 'North': 'NCA',\n",
       " 'Norton': 'NRN',\n",
       " 'Pinnacle': 'PIV',\n",
       " 'Richfort': 'RIF',\n",
       " 'Swanton': 'SWB',\n",
       " 'Aberdeen': 'ABE',\n",
       " 'Anacortes': 'ANA',\n",
       " 'Bellingham': 'BLI',\n",
       " 'Blaine': 'BLA',\n",
       " 'Boundary': 'BWA',\n",
       " 'Curlew': 'CUR',\n",
       " 'Danville': 'DVL',\n",
       " 'Everett': 'EVE',\n",
       " 'Ferry': 'FER',\n",
       " 'Friday': 'FRI',\n",
       " 'Frontier': 'FWA',\n",
       " 'Kalama': 'KLM',\n",
       " 'Laurier': 'LAU',\n",
       " 'Longview': 'LON',\n",
       " 'Metaline': 'MET',\n",
       " 'Neah': 'NEA',\n",
       " 'Nighthawk': 'NIG',\n",
       " 'Olympia': 'OLY',\n",
       " 'Oroville': 'ORO',\n",
       " 'Pasco': 'PWB',\n",
       " 'Point': 'PIR',\n",
       " 'Seattle': 'SEA',\n",
       " 'Spokane': 'SPO',\n",
       " 'Sumas': 'SUM',\n",
       " 'Tacoma': 'TAC',\n",
       " 'Tri-Cities': 'PSC',\n",
       " 'Vancouver': 'VCV',\n",
       " 'Algoma': 'AGM',\n",
       " 'Bayfield': 'BAY',\n",
       " 'Green': 'GRB',\n",
       " 'Manitowoc': 'MNW',\n",
       " 'Milwaukee': 'MIL',\n",
       " 'Truax': 'MSN',\n",
       " 'Clarksburg': 'CLK',\n",
       " 'Mercer': 'BLF',\n",
       " 'Casper': 'CSP',\n",
       " 'Not': 'XXX',\n",
       " 'Unidentifed': '888',\n",
       " 'Unknown': 'UNK',\n",
       " 'Calgary': 'CLG',\n",
       " 'Edmonton': 'EDA',\n",
       " 'Hakai': 'YHC',\n",
       " 'Halifax': 'HAL',\n",
       " 'Montreal': 'MON',\n",
       " 'Ottawa': 'OTT',\n",
       " 'Saskatoon': 'YXE',\n",
       " 'Toronto': 'TOR',\n",
       " 'Victoria': 'VIC',\n",
       " 'Winnipeg': 'WIN',\n",
       " 'Amsterdam-Schiphol': 'AMS',\n",
       " 'Aruba': 'ARB',\n",
       " 'Bankok': 'BAN',\n",
       " 'Beica': 'BEI',\n",
       " 'Beijing': 'PEK',\n",
       " 'Kindley': 'BDA',\n",
       " 'Bogota': 'BOG',\n",
       " 'Buenos': 'EZE',\n",
       " 'Cancun': 'CUN',\n",
       " 'Caravelas': 'CRQ',\n",
       " 'Carrasco': 'MVD',\n",
       " 'Dublin': 'DUB',\n",
       " 'Fougamou': 'FOU',\n",
       " 'Gen': 'HMO',\n",
       " 'Guadalajara': 'GDL',\n",
       " 'Hamilton': 'HAM',\n",
       " 'Inchon': 'ICN',\n",
       " 'Invalid': 'IWA',\n",
       " 'Kogalniceanu': 'CND',\n",
       " 'Labuha': 'LAH',\n",
       " 'Louis': 'DUR',\n",
       " 'Mangole': 'MAL',\n",
       " 'Medellin': 'MDE',\n",
       " 'Juarez': 'MEX',\n",
       " 'Middlesex': 'LHR',\n",
       " 'Nairobi': 'NBO',\n",
       " 'Nassau': 'NAS',\n",
       " 'Omar': 'PTY',\n",
       " 'Papua': 'SPV',\n",
       " 'Quito': 'UIO',\n",
       " 'Rome': 'RME',\n",
       " 'Sakon': 'SNO',\n",
       " 'Santana': 'SRO',\n",
       " 'Guarulhos': 'GRU',\n",
       " 'Shannon': 'SHA',\n",
       " 'Shillavo': 'HIL',\n",
       " 'Torokina': 'TOK',\n",
       " 'Veracruz': 'VER',\n",
       " 'Mexico': 'ZZZ',\n",
       " 'No': 'OSN',\n",
       " 'Abu': 'MAA',\n",
       " 'Magnolia': 'AG0',\n",
       " 'Bar': 'BHM',\n",
       " 'Birmingham': 'BHX',\n",
       " 'Suffolk': 'FOK',\n",
       " 'Lander': 'LND',\n",
       " 'Moline': 'MLI',\n",
       " 'Riverside': 'RIV'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANC': 'ANCHORAGE',\n",
       " 'BAR': 'BAKER',\n",
       " 'DAC': 'DALTONS',\n",
       " 'PIZ': 'DEW',\n",
       " 'DTH': 'DUTCH',\n",
       " 'EGL': 'EAGLE',\n",
       " 'FRB': 'FAIRBANKS',\n",
       " 'HOM': 'HOMER',\n",
       " 'HYD': 'HYDER',\n",
       " 'JUN': 'JUNEAU',\n",
       " '5KE': 'KETCHIKAN',\n",
       " 'KET': 'KETCHIKAN',\n",
       " 'MOS': 'MOSES',\n",
       " 'NIK': 'NIKISKI',\n",
       " 'NOM': 'NOM',\n",
       " 'PKC': 'POKER',\n",
       " 'ORI': 'PORT',\n",
       " 'SKA': 'SKAGWAY',\n",
       " 'SNP': 'ST',\n",
       " 'TKI': 'TOKEEN',\n",
       " 'WRA': 'WRANGELL',\n",
       " 'HSV': 'MADISON',\n",
       " 'MOB': 'MOBILE',\n",
       " 'LIA': 'LITTLE',\n",
       " 'ROG': 'ROGERS',\n",
       " 'DOU': 'DOUGLAS',\n",
       " 'LUK': 'LUKEVILLE',\n",
       " 'MAP': 'MARIPOSA',\n",
       " 'NAC': 'NACO',\n",
       " 'NOG': 'NOGALES',\n",
       " 'PHO': 'PHOENIX',\n",
       " 'POR': 'PORTAL',\n",
       " 'SLU': 'SAN',\n",
       " 'SAS': 'SASABE',\n",
       " 'TUC': 'TUCSON',\n",
       " 'YUI': 'YUMA',\n",
       " 'AND': 'ANDRADE',\n",
       " 'BUR': 'BURBANK',\n",
       " 'CAL': 'CALEXICO',\n",
       " 'CAO': 'CAMPO',\n",
       " 'FRE': 'FRESNO',\n",
       " 'ICP': 'IMPERIAL',\n",
       " 'LNB': 'LONG',\n",
       " 'LOS': 'LOS',\n",
       " 'BFL': 'MEADOWS',\n",
       " 'OAK': 'OAKLAND',\n",
       " 'ONT': 'ONTARIO',\n",
       " 'OTM': 'OTAY',\n",
       " 'BLT': 'PACIFIC',\n",
       " 'PSP': 'PALM',\n",
       " 'SAC': 'SACRAMENTO',\n",
       " 'SLS': 'SALINAS',\n",
       " 'SDP': 'SAN',\n",
       " 'SFR': 'SAN',\n",
       " 'SNJ': 'SAN',\n",
       " 'SLO': 'SAN',\n",
       " 'SLI': 'SAN',\n",
       " 'SPC': 'SAN',\n",
       " 'SYS': 'SAN',\n",
       " 'SAA': 'SANTA',\n",
       " 'STO': 'STOCKTON',\n",
       " 'TEC': 'TECATE',\n",
       " 'TRV': 'TRAVIS-AFB',\n",
       " 'APA': 'ARAPAHOE',\n",
       " 'ASE': 'ASPEN',\n",
       " 'COS': 'COLORADO',\n",
       " 'DEN': 'DENVER',\n",
       " 'DRO': 'LA',\n",
       " 'BDL': 'BRADLEY',\n",
       " 'BGC': 'BRIDGEPORT',\n",
       " 'GRT': 'GROTON',\n",
       " 'HAR': 'HARTFORD',\n",
       " 'NWH': 'NEW',\n",
       " 'NWL': 'NEW',\n",
       " 'TST': 'NEWINGTON',\n",
       " 'WAS': 'WASHINGTON',\n",
       " 'DOV': 'DOVER',\n",
       " 'DVD': 'DOVER-AFB',\n",
       " 'WLL': 'WILMINGTON',\n",
       " 'BOC': 'BOCAGRANDE',\n",
       " 'SRQ': 'BRADENTON',\n",
       " 'CAN': 'CAPE',\n",
       " 'DAB': 'DAYTONA',\n",
       " 'FRN': 'FERNANDINA',\n",
       " 'FTL': 'FORT',\n",
       " 'FMY': 'FORT',\n",
       " 'FPF': 'FORT',\n",
       " 'HUR': 'HURLBURT',\n",
       " 'GNV': 'J',\n",
       " 'JAC': 'JACKSONVILLE',\n",
       " 'KEY': 'KEY',\n",
       " 'LEE': 'LEESBURG',\n",
       " 'MLB': 'MELBOURNE',\n",
       " 'MIA': 'MIAMI',\n",
       " 'APF': 'NAPLES',\n",
       " 'OPF': 'OPA',\n",
       " 'ORL': 'ORLANDO',\n",
       " 'PAN': 'PANAMA',\n",
       " 'PEN': 'PENSACOLA',\n",
       " 'PCF': 'PORT',\n",
       " 'PEV': 'PORT',\n",
       " 'PSJ': 'PORT',\n",
       " 'SFB': 'SANFORD',\n",
       " 'SGJ': 'ST',\n",
       " 'SAU': 'ST',\n",
       " 'FPR': 'ST',\n",
       " 'SPE': 'ST',\n",
       " 'TAM': 'TAMPA',\n",
       " 'WPB': 'WEST',\n",
       " 'ATL': 'ATLANTA',\n",
       " 'BRU': 'BRUNSWICK',\n",
       " 'AGS': 'BUSH',\n",
       " 'SAV': 'SAVANNAH',\n",
       " 'AGA': 'AGANA',\n",
       " 'HHW': 'HONOLULU',\n",
       " 'OGG': 'KAHULUI',\n",
       " 'KOA': 'KEAHOLE-KONA',\n",
       " 'LIH': 'LIHUE',\n",
       " 'CID': 'CEDAR',\n",
       " 'DSM': 'DES',\n",
       " 'BOI': 'AIR',\n",
       " 'EPI': 'EASTPORT',\n",
       " 'IDA': 'FANNING',\n",
       " 'PTL': 'PORTHILL',\n",
       " 'SPI': 'CAPITAL',\n",
       " 'CHI': 'CHICAGO',\n",
       " 'DPA': 'DUPAGE',\n",
       " 'PIA': 'GREATER',\n",
       " 'RFD': 'GREATER',\n",
       " 'UGN': 'MEMORIAL',\n",
       " 'GAR': 'GARY',\n",
       " 'HMM': 'HAMMOND',\n",
       " 'INP': 'INDIANAPOLIS',\n",
       " 'MRL': 'MERRILLVILLE',\n",
       " 'SBN': 'SOUTH',\n",
       " 'ICT': 'MID-CONTINENT',\n",
       " 'LEX': 'BLUE',\n",
       " 'LOU': 'LOUISVILLE',\n",
       " 'BTN': 'BATON',\n",
       " 'LKC': 'LAKE',\n",
       " 'LAK': 'LAKE',\n",
       " 'MLU': 'MONROE',\n",
       " 'MGC': 'MORGAN',\n",
       " 'NOL': 'NEW',\n",
       " 'BOS': 'BOSTON',\n",
       " 'GLO': 'GLOUCESTER',\n",
       " 'BED': 'HANSCOM',\n",
       " 'LYN': 'LYNDEN',\n",
       " 'ADW': 'ANDREWS',\n",
       " 'BAL': 'BALTIMORE',\n",
       " 'MKG': 'MUSKEGON',\n",
       " 'PAX': 'PATUXENT',\n",
       " 'BGM': 'BANGOR',\n",
       " 'BOO': 'BOOTHBAY',\n",
       " 'BWM': 'BRIDGEWATER',\n",
       " 'BCK': 'BUCKPORT',\n",
       " 'CLS': 'CALAIS',\n",
       " 'CRB': 'CARIBOU',\n",
       " 'COB': 'COBURN',\n",
       " 'EST': 'EASTCOURT',\n",
       " 'EPT': 'EASTPORT',\n",
       " 'EPM': 'EASTPORT',\n",
       " 'FOR': 'FOREST',\n",
       " 'FTF': 'FORT',\n",
       " 'FTK': 'FORT',\n",
       " 'HML': 'HAMIIN',\n",
       " 'HTM': 'HOULTON',\n",
       " 'JKM': 'JACKMAN',\n",
       " 'KAL': 'KALISPEL',\n",
       " 'LIM': 'LIMESTONE',\n",
       " 'LUB': 'LUBEC',\n",
       " 'MAD': 'MADAWASKA',\n",
       " 'POM': 'PORTLAND',\n",
       " 'RGM': 'RANGELEY',\n",
       " 'SBR': 'SOUTH',\n",
       " 'SRL': 'ST',\n",
       " 'SPA': 'ST',\n",
       " 'VNB': 'VAN',\n",
       " 'VCB': 'VANCEBORO',\n",
       " 'AGN': 'ALGONAC',\n",
       " 'ALP': 'ALPENA',\n",
       " 'BCY': 'BAY',\n",
       " 'DET': 'DETROIT',\n",
       " 'GRP': 'GRAND',\n",
       " 'GRO': 'GROSSE',\n",
       " 'ISL': 'ISLE',\n",
       " 'MRC': 'MARINE',\n",
       " 'MRY': 'MARYSVILLE',\n",
       " 'PTK': 'OAKLAND',\n",
       " 'PHU': 'PORT',\n",
       " 'RBT': 'ROBERTS',\n",
       " 'SAG': 'SAGINAW',\n",
       " 'SSM': 'SAULT',\n",
       " 'SCL': 'ST',\n",
       " 'YIP': 'WILLOW',\n",
       " 'BAU': 'BAUDETTE',\n",
       " 'CAR': 'CARIBOU',\n",
       " 'GTF': 'Collapsed',\n",
       " 'INL': 'Collapsed',\n",
       " 'CRA': 'CRANE',\n",
       " 'MIC': 'CRYSTAL',\n",
       " 'DUL': 'DULUTH',\n",
       " 'ELY': 'ELY',\n",
       " 'GPM': 'GRAND',\n",
       " 'SVC': 'GRANT',\n",
       " \"INT'\\t=\\t'INT\": 'L',\n",
       " 'LAN': 'LANCASTER',\n",
       " 'MSP': 'MINN',\n",
       " 'LIN': 'NORTHERN',\n",
       " 'NOY': 'NOYES',\n",
       " 'PIN': 'PINE',\n",
       " '48Y': 'PINECREEK',\n",
       " 'RAN': 'RAINER',\n",
       " 'RST': 'ROCHESTER',\n",
       " 'ROS': 'ROSEAU',\n",
       " 'SPM': 'ST',\n",
       " 'WSB': 'WARROAD',\n",
       " 'WAR': 'WARROAD',\n",
       " 'KAN': 'KANSAS',\n",
       " 'SGF': 'SPRINGFIELD-BRANSON',\n",
       " 'STL': 'ST',\n",
       " 'WHI': 'WHITETAIL',\n",
       " 'WHM': 'WILD',\n",
       " 'GPT': 'BILOXI',\n",
       " 'GTR': 'GOLDEN',\n",
       " 'GUL': 'GULFPORT',\n",
       " 'PAS': 'PASCAGOULA',\n",
       " 'JAN': 'THOMPSON',\n",
       " 'BIL': 'BILLINGS',\n",
       " 'BTM': 'BUTTE',\n",
       " 'CHF': 'CHIEF',\n",
       " 'CTB': 'CUT',\n",
       " 'CUT': 'CUT',\n",
       " 'DLB': 'DEL',\n",
       " 'EUR': 'EUREKA',\n",
       " 'BZN': 'GALLATIN',\n",
       " 'FCA': 'GLACIER',\n",
       " 'GGW': 'GLASGOW',\n",
       " 'GRE': 'GREAT',\n",
       " 'HVR': 'HAVRE',\n",
       " 'HEL': 'HELENA',\n",
       " 'LWT': 'LEWISTON',\n",
       " 'MGM': 'MORGAN',\n",
       " 'OPH': 'OPHEIM',\n",
       " 'PIE': 'PIEGAN',\n",
       " 'RAY': 'RAYMOND',\n",
       " 'ROO': 'ROOSVILLE',\n",
       " 'SCO': 'SCOBEY',\n",
       " 'SWE': 'SWEETGTASS',\n",
       " 'TRL': 'TRIAL',\n",
       " 'TUR': 'TURNER',\n",
       " 'WCM': 'WILLOW',\n",
       " 'CLT': 'CHARLOTTE',\n",
       " 'FAY': 'FAYETTEVILLE',\n",
       " 'MRH': 'MOREHEAD',\n",
       " 'FOP': 'MORRIS',\n",
       " 'GSO': 'PIEDMONT',\n",
       " 'RDU': 'RALEIGH',\n",
       " 'SSC': 'SHAW',\n",
       " 'WIL': 'WILMINGTON',\n",
       " 'AMB': 'AMBROSE',\n",
       " 'ANT': 'ANTLER',\n",
       " 'CRY': 'CARBURY',\n",
       " 'DNS': 'DUNSEITH',\n",
       " 'FAR': 'FARGO',\n",
       " 'FRT': 'FORTUNA',\n",
       " 'GRF': 'GRAND',\n",
       " 'HNN': 'HANNAH',\n",
       " 'HNS': 'HANSBORO',\n",
       " 'MAI': 'MAIDA',\n",
       " 'MND': 'MINOT',\n",
       " 'NEC': 'NECHE',\n",
       " 'NOO': 'NOONAN',\n",
       " 'NRG': 'NORTHGATE',\n",
       " 'PEM': 'PEMBINA',\n",
       " 'SAR': 'SARLES',\n",
       " 'SHR': 'SHERWOOD',\n",
       " 'SJO': 'ST',\n",
       " 'WAL': 'WALHALLA',\n",
       " 'WHO': 'WESTHOPE',\n",
       " 'WND': 'WILLISTON',\n",
       " 'OMA': 'OMAHA',\n",
       " 'LEB': 'LEBANON',\n",
       " 'MHT': 'MANCHESTER',\n",
       " 'PNH': 'PITTSBURG',\n",
       " 'PSM': 'PORTSMOUTH',\n",
       " 'BYO': 'BAYONNE',\n",
       " 'CNJ': 'CAMDEN',\n",
       " 'HOB': 'HOBOKEN',\n",
       " 'JER': 'JERSEY',\n",
       " 'WRI': 'MC',\n",
       " 'MMU': 'MORRISTOWN',\n",
       " 'NEW': 'NEWARK',\n",
       " 'PER': 'PERTH',\n",
       " 'ACY': 'POMONA',\n",
       " 'ALA': 'ALAMAGORDO',\n",
       " 'ABQ': 'ALBUQUERQUE',\n",
       " 'ANP': 'ANTELOPE',\n",
       " 'CRL': 'CARLSBAD',\n",
       " 'COL': 'COLUMBUS',\n",
       " 'CDD': 'CRANE',\n",
       " 'DNM': 'DEMING',\n",
       " 'LAS': 'LAS',\n",
       " 'LOB': 'LORDSBURG',\n",
       " 'RUI': 'RUIDOSO',\n",
       " 'STR': 'SANTA',\n",
       " 'RNO': 'CANNON',\n",
       " 'FLX': 'FALLON',\n",
       " 'LVG': 'LAS',\n",
       " 'REN': 'RENO',\n",
       " 'ALB': 'ALBANY',\n",
       " 'AXB': 'ALEXANDRIA',\n",
       " 'BUF': 'BUFFALO',\n",
       " 'CNH': 'CANNON',\n",
       " 'CAP': 'CAPE',\n",
       " 'CHM': 'CHAMPLAIN',\n",
       " 'CHT': 'CHATEAUGAY',\n",
       " 'CLA': 'CLAYTON',\n",
       " 'FTC': 'FORT',\n",
       " 'LAG': 'LA',\n",
       " 'LEW': 'LEWISTON',\n",
       " 'MAS': 'MASSENA',\n",
       " 'MAG': 'MCGUIRE',\n",
       " 'MOO': 'MOORES',\n",
       " 'MRR': 'MORRISTOWN',\n",
       " 'NYC': 'NEW',\n",
       " 'NIA': 'NIAGARA',\n",
       " 'OGD': 'OGDENSBURG',\n",
       " 'OSW': 'OSWEGO',\n",
       " 'ELM': 'REGIONAL',\n",
       " 'ROC': 'ROCHESTER',\n",
       " 'ROU': 'ROUSES',\n",
       " 'SWF': 'STEWART',\n",
       " 'SYR': 'SYRACUSE',\n",
       " 'THO': 'THOUSAND',\n",
       " 'TRO': 'TROUT',\n",
       " 'WAT': 'WATERTOWN',\n",
       " 'HPN': 'WESTCHESTER',\n",
       " 'WRB': 'WHIRLPOOL',\n",
       " 'YOU': 'YOUNGSTOWN',\n",
       " 'AKR': 'AKRON',\n",
       " 'ATB': 'ASHTABULA',\n",
       " 'CIN': 'CINCINNATI',\n",
       " 'CLE': 'CLEVELAND',\n",
       " 'CLM': 'COLUMBUS',\n",
       " 'LOR': 'LORAIN',\n",
       " 'MBO': 'MARBLE',\n",
       " 'SDY': 'SANDUSKY',\n",
       " 'TOL': 'TOLEDO',\n",
       " 'OKC': 'OKLAHOMA',\n",
       " 'TUL': 'TULSA',\n",
       " 'AST': 'ASTORIA',\n",
       " 'COO': 'COOS',\n",
       " 'HIO': 'HILLSBORO',\n",
       " 'MED': 'MEDFORD',\n",
       " 'NPT': 'NEWPORT',\n",
       " 'POO': 'PORTLAND',\n",
       " 'PUT': 'PUT-IN-BAY',\n",
       " 'RDM': 'ROBERTS',\n",
       " 'ERI': 'ERIE',\n",
       " 'MDT': 'HARRISBURG',\n",
       " 'HSB': 'HARRISONBURG',\n",
       " 'PHI': 'PHILADELPHIA',\n",
       " 'PIT': 'PITTSBURG',\n",
       " 'AGU': 'AGUADILLA',\n",
       " 'BQN': 'BORINQUEN',\n",
       " 'JCP': 'CULEBRA',\n",
       " 'ENS': 'ENSENADA',\n",
       " 'FAJ': 'FAJARDO',\n",
       " 'HUM': 'HUMACAO',\n",
       " 'JOB': 'JOBOS',\n",
       " 'MAY': 'MAYAGUEZ',\n",
       " 'PON': 'PONCE',\n",
       " 'PSE': 'PONCE-MERCEDITA',\n",
       " 'SAJ': 'SAN',\n",
       " 'VQS': 'VIEQUES-ARPT',\n",
       " 'PRO': 'PROVIDENCE',\n",
       " 'PVD': 'THEODORE',\n",
       " 'CHL': 'CHARLESTON',\n",
       " 'CAE': 'COLUMBIA',\n",
       " 'GEO': 'GEORGETOWN',\n",
       " 'GSP': 'GREENVILLE',\n",
       " 'GRR': 'GREER',\n",
       " 'MYR': 'MYRTLE',\n",
       " 'SPF': 'BLACK',\n",
       " 'HON': 'HOWES',\n",
       " 'SAI': 'SAIPAN',\n",
       " 'TYS': 'MC',\n",
       " 'MEM': 'MEMPHIS',\n",
       " 'NSV': 'NASHVILLE',\n",
       " 'TRI': 'TRI',\n",
       " 'ADS': 'ADDISON',\n",
       " 'ADT': 'AMISTAD',\n",
       " 'ANZ': 'ANZALDUAS',\n",
       " 'AUS': 'AUSTIN',\n",
       " 'BEA': 'BEAUMONT',\n",
       " 'BBP': 'BIG',\n",
       " 'SCC': 'BP',\n",
       " 'BTC': 'BP',\n",
       " 'BOA': 'BRIDGE',\n",
       " 'BRO': 'BROWNSVILLE',\n",
       " 'CRP': 'CORPUS',\n",
       " 'DAL': 'DALLAS',\n",
       " 'DLR': 'DEL',\n",
       " 'DNA': 'DONNA',\n",
       " 'EGP': 'EAGLE',\n",
       " 'ELP': 'EL',\n",
       " 'FAB': 'FABENS',\n",
       " 'FAL': 'FALCON',\n",
       " 'FTH': 'FORT',\n",
       " 'AFW': 'FORT',\n",
       " 'FPT': 'FREEPORT',\n",
       " 'GAL': 'GALVESTON',\n",
       " 'HLG': 'HARLINGEN',\n",
       " 'HID': 'HIDALGO',\n",
       " 'HOU': 'HOUSTON',\n",
       " 'SGR': 'HULL',\n",
       " 'LLB': 'JUAREZ-LINCOLN',\n",
       " 'LCB': 'LAREDO',\n",
       " 'LRN': 'LAREDO',\n",
       " 'LAR': 'LAREDO',\n",
       " 'LSE': 'LOS',\n",
       " 'IND': 'LOS',\n",
       " 'LOI': 'LOS',\n",
       " 'MRS': 'MARFA',\n",
       " 'MCA': 'MCALLEN',\n",
       " 'MAF': 'ODESSA',\n",
       " 'PDN': 'PASO',\n",
       " 'PBB': 'PEACE',\n",
       " 'PHR': 'PHARR',\n",
       " 'PAR': 'PORT',\n",
       " 'ISB': 'PORT',\n",
       " 'POE': 'PORT',\n",
       " 'PRE': 'PRESIDIO',\n",
       " 'PGR': 'PROGRESO',\n",
       " 'RIO': 'RIO',\n",
       " 'ROM': 'ROMA',\n",
       " 'SNA': 'SAN',\n",
       " 'SNN': 'SANDERSON',\n",
       " 'VIB': 'VETERAN',\n",
       " 'YSL': 'YSLETA',\n",
       " 'CHA': 'CHARLOTTE',\n",
       " 'CHR': 'CHRISTIANSTED',\n",
       " 'CRU': 'CRUZ',\n",
       " 'FRK': 'FREDERIKSTED',\n",
       " 'STT': 'ST',\n",
       " 'LGU': 'CACHE',\n",
       " 'SLC': 'SALT',\n",
       " 'CHO': 'ALBEMARLE',\n",
       " 'DAA': 'DAVISON',\n",
       " 'HOP': 'HOPEWELL',\n",
       " 'HEF': 'MANASSAS',\n",
       " 'NWN': 'NEWPORT',\n",
       " 'NOR': 'NORFOLK',\n",
       " 'RCM': 'RICHMOND',\n",
       " 'ABS': 'ALBURG',\n",
       " 'ABG': 'ALBURG',\n",
       " 'BEB': 'BEEBE',\n",
       " 'BEE': 'BEECHER',\n",
       " 'BRG': 'BURLINGTON',\n",
       " 'CNA': 'CANAAN',\n",
       " 'DER': 'DERBY',\n",
       " 'DLV': 'DERBY',\n",
       " 'ERC': 'EAST',\n",
       " 'HIG': 'HIGHGATE',\n",
       " 'MOR': 'MORSES',\n",
       " 'NPV': 'NEWPORT',\n",
       " 'NRT': 'NORTH',\n",
       " 'NRN': 'NORTON',\n",
       " 'PIV': 'PINNACLE',\n",
       " 'RIF': 'RICHFORT',\n",
       " 'STA': 'ST',\n",
       " 'SWB': 'SWANTON',\n",
       " 'WBE': 'WEST',\n",
       " 'ABE': 'ABERDEEN',\n",
       " 'ANA': 'ANACORTES',\n",
       " 'BEL': 'BELLINGHAM',\n",
       " 'BLI': 'BELLINGHAM',\n",
       " 'BLA': 'BLAINE',\n",
       " 'BWA': 'BOUNDARY',\n",
       " 'CUR': 'CURLEW',\n",
       " 'DVL': 'DANVILLE',\n",
       " 'EVE': 'EVERETT',\n",
       " 'FER': 'FERRY',\n",
       " 'FRI': 'FRIDAY',\n",
       " 'FWA': 'FRONTIER',\n",
       " 'KLM': 'KALAMA',\n",
       " 'LAU': 'LAURIER',\n",
       " 'LON': 'LONGVIEW',\n",
       " 'MET': 'METALINE',\n",
       " 'MWH': 'MOSES',\n",
       " 'NEA': 'NEAH',\n",
       " 'NIG': 'NIGHTHAWK',\n",
       " 'OLY': 'OLYMPIA',\n",
       " 'ORO': 'OROVILLE',\n",
       " 'PWB': 'PASCO',\n",
       " 'PIR': 'POINT',\n",
       " 'PNG': 'PORT',\n",
       " 'PTO': 'PORT',\n",
       " 'SEA': 'SEATTLE',\n",
       " 'SPO': 'SPOKANE',\n",
       " 'SUM': 'SUMAS',\n",
       " 'TAC': 'TACOMA',\n",
       " 'PSC': 'TRI-CITIES',\n",
       " 'VAN': 'VANCOUVER',\n",
       " 'AGM': 'ALGOMA',\n",
       " 'BAY': 'BAYFIELD',\n",
       " 'GRB': 'GREEN',\n",
       " 'MNW': 'MANITOWOC',\n",
       " 'MIL': 'MILWAUKEE',\n",
       " 'MSN': 'TRUAX',\n",
       " 'CHS': 'CHARLESTON',\n",
       " 'CLK': 'CLARKSBURG',\n",
       " 'BLF': 'MERCER',\n",
       " 'CSP': 'CASPER',\n",
       " 'XXX': 'NOT',\n",
       " '888': 'UNIDENTIFED',\n",
       " 'UNK': 'UNKNOWN',\n",
       " 'CLG': 'CALGARY',\n",
       " 'EDA': 'EDMONTON',\n",
       " 'YHC': 'HAKAI',\n",
       " 'HAL': 'Halifax',\n",
       " 'MON': 'MONTREAL',\n",
       " 'OTT': 'OTTAWA',\n",
       " 'YXE': 'SASKATOON',\n",
       " 'TOR': 'TORONTO',\n",
       " 'VCV': 'VANCOUVER',\n",
       " 'VIC': 'VICTORIA',\n",
       " 'WIN': 'WINNIPEG',\n",
       " 'AMS': 'AMSTERDAM-SCHIPHOL',\n",
       " 'ARB': 'ARUBA',\n",
       " 'BAN': 'BANKOK',\n",
       " 'BEI': 'BEICA',\n",
       " 'PEK': 'BEIJING',\n",
       " 'BDA': 'KINDLEY',\n",
       " 'BOG': 'BOGOTA',\n",
       " 'EZE': 'BUENOS',\n",
       " 'CUN': 'CANCUN',\n",
       " 'CRQ': 'CARAVELAS',\n",
       " 'MVD': 'CARRASCO',\n",
       " 'DUB': 'DUBLIN',\n",
       " 'FOU': 'FOUGAMOU',\n",
       " 'FBA': 'FREEPORT',\n",
       " 'MTY': 'GEN',\n",
       " 'HMO': 'GEN',\n",
       " 'GCM': 'GRAND',\n",
       " 'GDL': 'GUADALAJARA',\n",
       " 'HAM': 'HAMILTON',\n",
       " 'ICN': 'INCHON',\n",
       " 'IWA': 'INVALID',\n",
       " 'CND': 'KOGALNICEANU',\n",
       " 'LAH': 'LABUHA',\n",
       " 'DUR': 'LOUIS',\n",
       " 'MAL': 'MANGOLE',\n",
       " 'MDE': 'MEDELLIN',\n",
       " 'MEX': 'JUAREZ',\n",
       " 'LHR': 'MIDDLESEX',\n",
       " 'NBO': 'NAIROBI',\n",
       " 'NAS': 'NASSAU',\n",
       " 'NCA': 'NORTH',\n",
       " 'PTY': 'OMAR',\n",
       " 'SPV': 'PAPUA',\n",
       " 'UIO': 'QUITO',\n",
       " 'RIT': 'ROME',\n",
       " 'SNO': 'SAKON',\n",
       " 'SLP': 'SAN',\n",
       " 'SAN': 'SAN',\n",
       " 'SRO': 'SANTANA',\n",
       " 'GRU': 'GUARULHOS',\n",
       " 'SHA': 'SHANNON',\n",
       " 'HIL': 'SHILLAVO',\n",
       " 'TOK': 'TOROKINA',\n",
       " 'VER': 'VERACRUZ',\n",
       " 'LGW': 'WEST',\n",
       " 'ZZZ': 'MEXICO',\n",
       " 'CHN': 'No',\n",
       " 'CNC': 'CANNON',\n",
       " 'MAA': 'Abu',\n",
       " 'AG0': 'MAGNOLIA',\n",
       " 'BHM': 'BAR',\n",
       " 'BHX': 'BIRMINGHAM',\n",
       " 'CAK': 'AKRON',\n",
       " 'FOK': 'SUFFOLK',\n",
       " 'LND': 'LANDER',\n",
       " 'MAR': 'MARFA',\n",
       " 'MLI': 'MOLINE',\n",
       " 'RIV': 'RIVERSIDE',\n",
       " 'RME': 'ROME',\n",
       " 'VNY': 'VAN',\n",
       " 'YUM': 'YUMA',\n",
       " 'FRG': 'Collapsed',\n",
       " 'HRL': 'Collapsed',\n",
       " 'ISP': 'Collapsed',\n",
       " 'JSJ': 'Collapsed',\n",
       " 'BUS': 'Collapsed',\n",
       " 'IAG': 'Collapsed',\n",
       " 'PHN': 'Collapsed',\n",
       " 'STN': 'Collapsed',\n",
       " 'VMB': 'Collapsed',\n",
       " 'T01': 'Collapsed',\n",
       " 'PHF': 'No',\n",
       " 'DRV': 'No',\n",
       " 'FTB': 'No',\n",
       " 'GAC': 'No',\n",
       " 'GMT': 'No',\n",
       " 'JFA': 'No',\n",
       " 'JMZ': 'No',\n",
       " 'NC8': 'No',\n",
       " 'NYL': 'No',\n",
       " 'OAI': 'No',\n",
       " 'PCW': 'No',\n",
       " 'WA5': 'No',\n",
       " 'WTR': 'No',\n",
       " 'X96': 'No',\n",
       " 'XNA': 'No',\n",
       " 'YGF': 'No',\n",
       " '5T6': 'No',\n",
       " '060': 'No',\n",
       " 'SP0': 'No',\n",
       " 'W55': 'No',\n",
       " 'X44': 'No',\n",
       " 'AUH': 'No',\n",
       " 'RYY': 'No',\n",
       " 'SUS': 'No',\n",
       " '74S': 'No',\n",
       " 'ATW': 'No',\n",
       " 'CPX': 'No',\n",
       " 'MTH': 'No',\n",
       " 'PFN': 'No',\n",
       " 'SCH': 'No',\n",
       " 'ASI': 'No',\n",
       " 'BKF': 'No',\n",
       " 'DAY': 'No',\n",
       " 'Y62': 'No',\n",
       " 'AG': 'No',\n",
       " 'BCM': 'No',\n",
       " 'DEC': 'No',\n",
       " 'PLB': 'No',\n",
       " 'CXO': 'No',\n",
       " 'JBQ': 'No',\n",
       " 'JIG': 'No',\n",
       " 'OGS': 'No',\n",
       " 'TIW': 'No',\n",
       " 'OTS': 'No',\n",
       " 'AMT': 'No',\n",
       " 'EGE': 'No',\n",
       " 'GPI': 'No',\n",
       " 'NGL': 'No',\n",
       " 'OLM': 'No',\n",
       " '.GA': 'No',\n",
       " 'CLX': 'No',\n",
       " 'CP ': 'No',\n",
       " 'FSC': 'No',\n",
       " 'NK': 'No',\n",
       " 'ADU': 'No',\n",
       " 'AKT': 'No',\n",
       " 'LIT': 'No',\n",
       " 'A2A': 'No',\n",
       " 'OSN': 'No'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       G       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599212\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.788</td>\n",
       "      <td>3.624</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.283</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.051</td>\n",
       "      <td>1.347</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  rhus   \n",
       "1  1743-12-01                 NaN                            NaN  rhus   \n",
       "2  1744-01-01                 NaN                            NaN  rhus   \n",
       "3  1744-02-01                 NaN                            NaN  rhus   \n",
       "4  1744-03-01                 NaN                            NaN  rhus   \n",
       "5  1744-04-01               5.788                          3.624  rhus   \n",
       "6  1744-05-01              10.644                          1.283  rhus   \n",
       "7  1744-06-01              14.051                          1.347  rhus   \n",
       "8  1744-07-01              16.082                          1.396  rhus   \n",
       "9  1744-08-01                 NaN                            NaN  rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  \n",
       "5  Denmark   57.05N    10.33E  \n",
       "6  Denmark   57.05N    10.33E  \n",
       "7  Denmark   57.05N    10.33E  \n",
       "8  Denmark   57.05N    10.33E  \n",
       "9  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tempa))\n",
    "tempa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting spark session\n",
    "Using spark to read in the sas immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/27 18:29:31 WARN Utils: Your hostname, Terminator.local resolves to a loopback address: 127.0.0.1; using 192.168.178.97 instead (on interface en0)\n",
      "23/02/27 18:29:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://repos.spark-packages.org/ added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /Users/terminator/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/terminator/.ivy2/jars\n",
      "saurfang#spark-sas7bdat added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f32a229a-0851-4025-9a14-6ad31d845d79;1.0\n",
      "\tconfs: [default]\n",
      "\tfound saurfang#spark-sas7bdat;2.0.0-s_2.11 in spark-packages\n",
      "\tfound com.epam#parso;2.0.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/terminator/anaconda3/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.logging.log4j#log4j-api-scala_2.11;2.7 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.11.8 in central\n",
      ":: resolution report :: resolve 171ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.epam#parso;2.0.8 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-api-scala_2.11;2.7 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\tsaurfang#spark-sas7bdat;2.0.0-s_2.11 from spark-packages in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f32a229a-0851-4025-9a14-6ad31d845d79\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/6ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/27 18:29:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "spark.conf.set(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_imm = spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imm.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/27 18:29:44 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid    |i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum        |fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |CA     |20582.0|40.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1976.0 |10292016|F     |null  |QF     |9.495387003E10|00011|B1      |\n",
      "|5748518.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |NV     |20591.0|32.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1984.0 |10292016|F     |null  |VA     |9.495562283E10|00007|B1      |\n",
      "|5748519.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |WA     |20582.0|29.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1987.0 |10292016|M     |null  |DL     |9.495640653E10|00040|B1      |\n",
      "|5748520.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |WA     |20588.0|29.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1987.0 |10292016|F     |null  |DL     |9.495645143E10|00040|B1      |\n",
      "|5748521.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |WA     |20588.0|28.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1988.0 |10292016|M     |null  |DL     |9.495638813E10|00040|B1      |\n",
      "|5748522.0|2016.0|4.0   |245.0 |464.0 |HHW    |20574.0|1.0    |HI     |20579.0|57.0  |2.0    |1.0  |20160430|ACK     |null |G      |O      |null   |M      |1959.0 |10292016|M     |null  |NZ     |9.498180283E10|00010|B2      |\n",
      "|5748523.0|2016.0|4.0   |245.0 |464.0 |HHW    |20574.0|1.0    |HI     |20586.0|66.0  |2.0    |1.0  |20160430|ACK     |null |G      |O      |null   |M      |1950.0 |10292016|F     |null  |NZ     |9.497968993E10|00010|B2      |\n",
      "|5748524.0|2016.0|4.0   |245.0 |464.0 |HHW    |20574.0|1.0    |HI     |20586.0|41.0  |2.0    |1.0  |20160430|ACK     |null |G      |O      |null   |M      |1975.0 |10292016|F     |null  |NZ     |9.497974673E10|00010|B2      |\n",
      "|5748525.0|2016.0|4.0   |245.0 |464.0 |HOU    |20574.0|1.0    |FL     |20581.0|27.0  |2.0    |1.0  |20160430|ACK     |null |G      |O      |null   |M      |1989.0 |10292016|M     |null  |NZ     |9.497324663E10|00028|B2      |\n",
      "|5748526.0|2016.0|4.0   |245.0 |464.0 |LOS    |20574.0|1.0    |CA     |20581.0|26.0  |2.0    |1.0  |20160430|ACK     |null |G      |O      |null   |M      |1990.0 |10292016|F     |null  |NZ     |9.501354793E10|00002|B2      |\n",
      "|5748527.0|2016.0|4.0   |245.0 |504.0 |NEW    |20574.0|1.0    |MA     |20576.0|44.0  |2.0    |1.0  |20160430|GUZ     |null |G      |O      |null   |M      |1972.0 |10292016|M     |null  |UA     |9.493828593E10|01215|B2      |\n",
      "|5748528.0|2016.0|4.0   |245.0 |504.0 |LOS    |20574.0|1.0    |null   |20575.0|39.0  |2.0    |1.0  |20160430|GUZ     |null |G      |O      |null   |M      |1977.0 |10292016|M     |null  |CM     |9.501810463E10|00472|B2      |\n",
      "|5748529.0|2016.0|4.0   |245.0 |504.0 |WAS    |20574.0|1.0    |VA     |20596.0|38.0  |2.0    |1.0  |20160430|PNM     |null |G      |O      |null   |M      |1978.0 |10292016|M     |null  |CM     |9.492489983E10|00488|B2      |\n",
      "|5748530.0|2016.0|4.0   |245.0 |504.0 |LOS    |20574.0|1.0    |CA     |20577.0|56.0  |2.0    |1.0  |20160430|PNM     |null |G      |O      |null   |M      |1960.0 |10292016|F     |null  |CM     |9.492648103E10|00302|B2      |\n",
      "|5748531.0|2016.0|4.0   |245.0 |504.0 |LOS    |20574.0|1.0    |CA     |20577.0|38.0  |2.0    |1.0  |20160430|PNM     |null |G      |O      |null   |M      |1978.0 |10282016|M     |null  |CM     |9.492629303E10|00302|B2      |\n",
      "|5748532.0|2016.0|4.0   |245.0 |504.0 |MIA    |20574.0|1.0    |FL     |20581.0|53.0  |2.0    |1.0  |20160430|PNM     |null |G      |O      |null   |M      |1963.0 |10292016|F     |null  |CM     |9.500640513E10|00430|B2      |\n",
      "|5748534.0|2016.0|4.0   |245.0 |528.0 |SFR    |20574.0|1.0    |CA     |null   |84.0  |2.0    |1.0  |20160430|HNK     |null |G      |null   |null   |null   |1932.0 |10282016|F     |null  |CX     |9.492476223E10|00872|B2      |\n",
      "|5748876.0|2016.0|4.0   |245.0 |582.0 |HOU    |20574.0|1.0    |TX     |20583.0|43.0  |1.0    |1.0  |20160430|GUZ     |null |G      |O      |null   |M      |1973.0 |10292016|M     |null  |UA     |9.499463063E10|05574|B1      |\n",
      "|5748877.0|2016.0|4.0   |245.0 |582.0 |HOU    |20574.0|1.0    |TX     |20583.0|30.0  |1.0    |1.0  |20160430|GUZ     |null |G      |O      |null   |M      |1986.0 |10292016|F     |null  |UA     |9.499447663E10|05574|B1      |\n",
      "|5748881.0|2016.0|4.0   |245.0 |582.0 |LOS    |20574.0|1.0    |CA     |20575.0|34.0  |2.0    |1.0  |20160430|SHG     |null |G      |O      |null   |M      |1982.0 |10292016|M     |null  |AM     |9.496770903E10|00646|B2      |\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imm.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(i94mon)|\n",
      "+-----------+\n",
      "|        4.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imm.select(F.max(df_imm.i94mon)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 0          1743-11-01\n",
       "1          1743-12-01\n",
       "2          1744-01-01\n",
       "3          1744-02-01\n",
       "4          1744-03-01\n",
       "              ...    \n",
       "8599207    2013-05-01\n",
       "8599208    2013-06-01\n",
       "8599209    2013-07-01\n",
       "8599210    2013-08-01\n",
       "8599211    2013-09-01\n",
       "Name: dt, Length: 8599212, dtype: object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempa.dt.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "tempa_duplicates = tempa[tempa.duplicated()]\n",
    "print(tempa_duplicates)\n",
    "# no duplictes in temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
      "1        1743-12-01                 NaN                            NaN   \n",
      "2        1744-01-01                 NaN                            NaN   \n",
      "3        1744-02-01                 NaN                            NaN   \n",
      "4        1744-03-01                 NaN                            NaN   \n",
      "9        1744-08-01                 NaN                            NaN   \n",
      "...             ...                 ...                            ...   \n",
      "8596076  1752-06-01                 NaN                            NaN   \n",
      "8596077  1752-07-01                 NaN                            NaN   \n",
      "8596078  1752-08-01                 NaN                            NaN   \n",
      "8596079  1752-09-01                 NaN                            NaN   \n",
      "8599211  2013-09-01                 NaN                            NaN   \n",
      "\n",
      "           City      Country Latitude Longitude  \n",
      "1         rhus      Denmark   57.05N    10.33E  \n",
      "2         rhus      Denmark   57.05N    10.33E  \n",
      "3         rhus      Denmark   57.05N    10.33E  \n",
      "4         rhus      Denmark   57.05N    10.33E  \n",
      "9         rhus      Denmark   57.05N    10.33E  \n",
      "...         ...          ...      ...       ...  \n",
      "8596076  Zwolle  Netherlands   52.24N     5.26E  \n",
      "8596077  Zwolle  Netherlands   52.24N     5.26E  \n",
      "8596078  Zwolle  Netherlands   52.24N     5.26E  \n",
      "8596079  Zwolle  Netherlands   52.24N     5.26E  \n",
      "8599211  Zwolle  Netherlands   52.24N     5.26E  \n",
      "\n",
      "[364130 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "mask = tempa.isna().any(axis=1)\n",
    "tempa_na = tempa[mask]\n",
    "print(tempa_na)\n",
    "# a fair amount of records with NaN average temperatures, these will be removed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "##### Cleaning the temperature data\n",
    "The world temperature data only goes until 2013, it also includes temperatures for 1743. These records are not necessary for this dataset and will be removed; we will keep the average temperatures of 2012 given that the average annual temperature was 56.6 F which is around the same as the average annual temperature of 2016 (56.2 F). We are dealing with 2016 immigration data and only have temperature data until 2013. With the annual averages being around the same we can more accurately use the 2012 temperature data compared to the 2013 data (average annual temperature was 53.3F, source: https://www.weather.gov/media/slc/ClimateBook/Annual%20Average%20Temperature%20By%20Year.pdf). More concretely we only have 2016 April immigration data so we will only use 2012 April average temperature in the function. \\\n",
    "Moreover, records that do not have an average temperature will be removed. \\\n",
    "Lastly, only cities in the US are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73710 entries, 3218 to 8599211\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   dt                             73710 non-null  object \n",
      " 1   AverageTemperature             70640 non-null  float64\n",
      " 2   AverageTemperatureUncertainty  70640 non-null  float64\n",
      " 3   City                           73710 non-null  object \n",
      " 4   Country                        73710 non-null  object \n",
      " 5   Latitude                       73710 non-null  object \n",
      " 6   Longitude                      73710 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tempa = tempa[tempa[\"dt\"] >= '2012-01-01']\n",
    "tempa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70640 entries, 3218 to 8599210\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   dt                             70640 non-null  object \n",
      " 1   AverageTemperature             70640 non-null  float64\n",
      " 2   AverageTemperatureUncertainty  70640 non-null  float64\n",
      " 3   City                           70640 non-null  object \n",
      " 4   Country                        70640 non-null  object \n",
      " 5   Latitude                       70640 non-null  object \n",
      " 6   Longitude                      70640 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tempa = tempa[tempa['AverageTemperature'].notna()]\n",
    "tempa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5396 entries, 49859 to 8439246\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   dt                             5396 non-null   object \n",
      " 1   AverageTemperature             5396 non-null   float64\n",
      " 2   AverageTemperatureUncertainty  5396 non-null   float64\n",
      " 3   City                           5396 non-null   object \n",
      " 4   Country                        5396 non-null   object \n",
      " 5   Latitude                       5396 non-null   object \n",
      " 6   Longitude                      5396 non-null   object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 337.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tempa = tempa[tempa['Country'] == 'United States']\n",
    "tempa.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning the i94 ports\n",
    "Both the immigration and the temperature data need to be cleaned to only display the relevant i94 ports. The labels description SAS file is used for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096242\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid    |i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum        |fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |CA     |20582.0|40.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1976.0 |10292016|F     |null  |QF     |9.495387003E10|00011|B1      |\n",
      "|5748518.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |NV     |20591.0|32.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1984.0 |10292016|F     |null  |VA     |9.495562283E10|00007|B1      |\n",
      "|5748519.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |WA     |20582.0|29.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1987.0 |10292016|M     |null  |DL     |9.495640653E10|00040|B1      |\n",
      "|5748520.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |WA     |20588.0|29.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1987.0 |10292016|F     |null  |DL     |9.495645143E10|00040|B1      |\n",
      "|5748521.0|2016.0|4.0   |245.0 |438.0 |LOS    |20574.0|1.0    |WA     |20588.0|28.0  |1.0    |1.0  |20160430|SYD     |null |G      |O      |null   |M      |1988.0 |10292016|M     |null  |DL     |9.495638813E10|00040|B1      |\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imm_cleaned = df_imm[(df_imm.i94port.isin(list(i94_ports.keys())))]\n",
    "print(df_imm_cleaned.count())\n",
    "df_imm_cleaned.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140284</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>0.410</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140285</th>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>1.527</td>\n",
       "      <td>0.319</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140286</th>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>10.109</td>\n",
       "      <td>0.442</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140287</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>9.195</td>\n",
       "      <td>0.412</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140288</th>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>18.921</td>\n",
       "      <td>0.322</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165133</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>17.134</td>\n",
       "      <td>0.188</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165134</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>22.919</td>\n",
       "      <td>0.245</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165135</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>25.658</td>\n",
       "      <td>0.304</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165136</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>22.722</td>\n",
       "      <td>0.241</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165137</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>19.643</td>\n",
       "      <td>1.050</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1532 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "140284   2012-01-01              -0.344                          0.410   \n",
       "140285   2012-02-01               1.527                          0.319   \n",
       "140286   2012-03-01              10.109                          0.442   \n",
       "140287   2012-04-01               9.195                          0.412   \n",
       "140288   2012-05-01              18.921                          0.322   \n",
       "...             ...                 ...                            ...   \n",
       "8165133  2013-05-01              17.134                          0.188   \n",
       "8165134  2013-06-01              22.919                          0.245   \n",
       "8165135  2013-07-01              25.658                          0.304   \n",
       "8165136  2013-08-01              22.722                          0.241   \n",
       "8165137  2013-09-01              19.643                          1.050   \n",
       "\n",
       "               City        Country Latitude Longitude  \n",
       "140284        Akron  United States   40.99N    80.95W  \n",
       "140285        Akron  United States   40.99N    80.95W  \n",
       "140286        Akron  United States   40.99N    80.95W  \n",
       "140287        Akron  United States   40.99N    80.95W  \n",
       "140288        Akron  United States   40.99N    80.95W  \n",
       "...             ...            ...      ...       ...  \n",
       "8165133  Washington  United States   39.38N    76.99W  \n",
       "8165134  Washington  United States   39.38N    76.99W  \n",
       "8165135  Washington  United States   39.38N    76.99W  \n",
       "8165136  Washington  United States   39.38N    76.99W  \n",
       "8165137  Washington  United States   39.38N    76.99W  \n",
       "\n",
       "[1532 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tempa = tempa[(tempa[\"City\"].isin(list(cities.keys())))]\n",
    "#print(len(tempa))\n",
    "tempa[(tempa[\"City\"].isin(list(cities.keys())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally adding the i94_port to the temperature dataset\n",
    "tempa['i94port'] = tempa[\"City\"].map(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>i94port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49859</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>7.996</td>\n",
       "      <td>0.204</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49860</th>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>8.434</td>\n",
       "      <td>0.252</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49861</th>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>15.628</td>\n",
       "      <td>0.173</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49862</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>21.069</td>\n",
       "      <td>0.388</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49863</th>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>24.698</td>\n",
       "      <td>0.323</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8439242</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>15.544</td>\n",
       "      <td>0.281</td>\n",
       "      <td>Yonkers</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>74.56W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8439243</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>20.892</td>\n",
       "      <td>0.273</td>\n",
       "      <td>Yonkers</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>74.56W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8439244</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>24.722</td>\n",
       "      <td>0.279</td>\n",
       "      <td>Yonkers</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>74.56W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8439245</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>21.001</td>\n",
       "      <td>0.323</td>\n",
       "      <td>Yonkers</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>74.56W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8439246</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>17.408</td>\n",
       "      <td>1.048</td>\n",
       "      <td>Yonkers</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>74.56W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5396 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "49859    2012-01-01               7.996                          0.204   \n",
       "49860    2012-02-01               8.434                          0.252   \n",
       "49861    2012-03-01              15.628                          0.173   \n",
       "49862    2012-04-01              21.069                          0.388   \n",
       "49863    2012-05-01              24.698                          0.323   \n",
       "...             ...                 ...                            ...   \n",
       "8439242  2013-05-01              15.544                          0.281   \n",
       "8439243  2013-06-01              20.892                          0.273   \n",
       "8439244  2013-07-01              24.722                          0.279   \n",
       "8439245  2013-08-01              21.001                          0.323   \n",
       "8439246  2013-09-01              17.408                          1.048   \n",
       "\n",
       "            City        Country Latitude Longitude i94port  \n",
       "49859    Abilene  United States   32.95N   100.53W     NaN  \n",
       "49860    Abilene  United States   32.95N   100.53W     NaN  \n",
       "49861    Abilene  United States   32.95N   100.53W     NaN  \n",
       "49862    Abilene  United States   32.95N   100.53W     NaN  \n",
       "49863    Abilene  United States   32.95N   100.53W     NaN  \n",
       "...          ...            ...      ...       ...     ...  \n",
       "8439242  Yonkers  United States   40.99N    74.56W     NaN  \n",
       "8439243  Yonkers  United States   40.99N    74.56W     NaN  \n",
       "8439244  Yonkers  United States   40.99N    74.56W     NaN  \n",
       "8439245  Yonkers  United States   40.99N    74.56W     NaN  \n",
       "8439246  Yonkers  United States   40.99N    74.56W     NaN  \n",
       "\n",
       "[5396 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the exploration above we want to filter the i94 immigration data on valid i94 ports. \\\n",
    "We need the temperature data to be in a spark dataframe as well. \\\n",
    "From the temperature data we can see that it could be enriched with the i94 port code on city name, and then filter the temperature data without valid i94 ports as well as the records without average temperature data. \\\n",
    "For the immigration table we could use the columns [\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\"] and for the temperature table we could use [\"AverageTemperature\", \"City\", \"Country\", \"Latitude\", \"Longitude\", \"i94port\"]. \\\n",
    "A mixture of these two tables will result in the fact table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single function to clean the temperature data\n",
    "def clean_temperature(tempa, cities):\n",
    "    \"\"\"\n",
    "    Function that cleans the pandas temperature dataframe. \n",
    "    Takes as input the temperature pandas dataframe and the cities dictionary created from the SAS labels file\n",
    "    Average temperature of 2012 April is selected, Nan average temperature records are removed, only cities in the US are kept, and the City's i94 port needs to be found.\n",
    "    The subset of columns that are deemed to be useful for the fact table are selected.\n",
    "    Finally the pandas dataframe is converted to a spark dataframe to coincide with the immigration dataframe.\n",
    "    \"\"\"\n",
    "    tempa = tempa[(tempa[\"dt\"] >= '2012-04-01') & (tempa[\"dt\"] < '2012-05-01')]\n",
    "    tempa = tempa[tempa['AverageTemperature'].notna()]\n",
    "    tempa = tempa[tempa['Country'] == 'United States']\n",
    "    tempa = tempa[(tempa[\"City\"].isin(list(cities.keys())))]\n",
    "    tempa['i94port'] = tempa[\"City\"].map(cities)\n",
    "    tempa = tempa.loc[:, [\"dt\", \"AverageTemperature\", \"City\", \"Country\", \"Latitude\", \"Longitude\", \"i94port\"]]\n",
    "    tempa_table = spark.createDataFrame(tempa)\n",
    "    return tempa_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terminator/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/Users/terminator/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "tempa_table = clean_temperature(tempa, cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking on clean temperature table if any of the columns contain null or Nan values. The following continues the data exploration and is the pre-cursor to the data quality check functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|(isnan(City) OR (City IS NULL))|\n",
      "+-------------------------------+\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "|                          false|\n",
      "+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempa_table.select((isnan(\"City\") | tempa_table[\"City\"].isNull())).show()\n",
    "#tempa_table.select(count(isnan(\"City\") | tempa_table[\"City\"].isNull())).collect()[0]\n",
    "#tempa_table.filter((isnan(c) | tempa_table[c].isNull()).alias(c) for c in tempa_table.columns).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single function to clean the immigration data\n",
    "def clean_immigration(df_imm, i94_ports):\n",
    "    \"\"\"\n",
    "    Function to clean immigration spark dataframe.\n",
    "    Inputs: Spark immigration dataframe and i94_ports dictionary\n",
    "    Filters out records where the i94 port does not match the i94_ports dictionary.\n",
    "    The selected subset of columns are to be used in the fact table.\n",
    "    Returns a cleaned immigration spark dataframe. \n",
    "    \"\"\"\n",
    "    df_imm = df_imm.filter(df_imm.i94port.isin(list(i94_ports.keys())))\n",
    "    imm_table = df_imm.select([\"cicid\", \"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"depdate\", \"i94visa\"])\n",
    "    return imm_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_table = clean_immigration(df_imm, i94_ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+-------+-------+-------+-------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94port|arrdate|depdate|i94visa|\n",
      "+-----+-----+------+------+-------+-------+-------+-------+\n",
      "+-----+-----+------+------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_table.filter(isnan(\"depdate\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+-------+-------+-------+-------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94port|arrdate|depdate|i94visa|\n",
      "+---------+------+------+------+-------+-------+-------+-------+\n",
      "|5748534.0|2016.0|   4.0| 245.0|    SFR|20574.0|   null|    2.0|\n",
      "|5748908.0|2016.0|   4.0| 249.0|    LOS|20574.0|   null|    2.0|\n",
      "|5748930.0|2016.0|   4.0| 249.0|    SEA|20574.0|   null|    2.0|\n",
      "|5748945.0|2016.0|   4.0| 249.0|    SFR|20574.0|   null|    2.0|\n",
      "|5748946.0|2016.0|   4.0| 249.0|    SFR|20574.0|   null|    2.0|\n",
      "|5748948.0|2016.0|   4.0| 249.0|    BOS|20574.0|   null|    3.0|\n",
      "|5748968.0|2016.0|   4.0| 250.0|    WAS|20574.0|   null|    1.0|\n",
      "|5749006.0|2016.0|   4.0| 250.0|    CHI|20574.0|   null|    2.0|\n",
      "|5749007.0|2016.0|   4.0| 250.0|    CHI|20574.0|   null|    2.0|\n",
      "|5749009.0|2016.0|   4.0| 250.0|    CHI|20574.0|   null|    2.0|\n",
      "|5749064.0|2016.0|   4.0| 250.0|    LOS|20574.0|   null|    2.0|\n",
      "|5749094.0|2016.0|   4.0| 251.0|    NYC|20573.0|   null|    2.0|\n",
      "|5749225.0|2016.0|   4.0| 251.0|    BOS|20574.0|   null|    1.0|\n",
      "|5749226.0|2016.0|   4.0| 251.0|    BOS|20574.0|   null|    1.0|\n",
      "|5749261.0|2016.0|   4.0| 251.0|    CLT|20574.0|   null|    2.0|\n",
      "|5749311.0|2016.0|   4.0| 251.0|    NEW|20574.0|   null|    1.0|\n",
      "|5749320.0|2016.0|   4.0| 251.0|    NEW|20574.0|   null|    1.0|\n",
      "|5749342.0|2016.0|   4.0| 251.0|    NEW|20574.0|   null|    3.0|\n",
      "|5749464.0|2016.0|   4.0| 251.0|    NEW|20574.0|   null|    3.0|\n",
      "|5749518.0|2016.0|   4.0| 251.0|    NYC|20574.0|   null|    1.0|\n",
      "+---------+------+------+------+-------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_table.filter(imm_table[\"depdate\"].isNull()).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that some records have empty departure dates. Whilst this is not strange at first sight, it is a little strange for the US. This is because at the port of arrival all visitors are required to submit an address for their stay as well as dates for their departure, including flight tickets. There are obviously occasions where the departure date of a visit is to be determined later, but this would constitute a flag for immigration staff and further questioning would take place. In this dataset it could be possible that the lack of the departure date is a data quality issue, and that it will perhaps be added in updates. The immigration table at the source is a transaction table where new records get appended, an update on existing records therefore seems unlikely. \\\n",
    "In further iterations of this immigration insights table it would be wise to further investigate what the nature and the impact is of the lack of a departure date as a question in the likes of \"how many visitors are currently in the US\" is very viable and interesting for users of the table to ask. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model and Data Dictionary\n",
    "\"Map out the conceptual data model and explain why you chose that model.\"\n",
    "\n",
    "We are using the immigration and global temperatures datasets. They are cleaned with the I94 SAS Labels Descriptions file. After the cleaning step we have two dimensional tables with the following structure:\n",
    "##### Immigration standardized table\n",
    "| Column name | data type | description |\n",
    "| ----------- | --------- | ------------------------------- |\n",
    "|**cicid**      | **FLOAT**       | **immigration record id**|\n",
    "| i94yr       | INT       | year of immigration record      |\n",
    "| i94mon      | INT       | month of immigration record      |\n",
    "| i94cit      | VARCHAR(3)| origin country code               |\n",
    "| i94port     | CHAR(3)   | US city code of arrival port      |\n",
    "| arrdate     | FLOAT     | arrival date at US port in sas date format      |\n",
    "| depdate     | FLOAT     | departure date from US in sas date format      |\n",
    "| i94visa     | FLOAT     | reason for visit      |\n",
    "\n",
    "Each row in the immigration record table contains information on aliens entering in US ports of arrival. The unique visit record is marked with a **cicid**. \n",
    "##### Temperature standardized table\n",
    "| Column name | data type | description |\n",
    "| ----------- | --------- | ------------------------------- |\n",
    "| dt       | VARCHAR(256)       | month of temperature record in yyyy-mm-dd     |\n",
    "| AverageTemperature      | FLOAT       | average temperature for recorded month      |\n",
    "| City      | VARCHAR(256)| city of temperature record               |\n",
    "| Country     | VARCHAR(256)   | country of temperature record      |\n",
    "| Latitude     | VARCHAR(256)     | latitude      |\n",
    "| Longitude     | VARCHAR(256)     | longitude       |\n",
    "| i94port     | CHAR(3)     | US city code of arrival port      |\n",
    "\n",
    "Each row denotes the average temperature for a given month of a given city. The combination of the **dt** and City columns create a unique record.\n",
    "##### Immigration optimized fact table\n",
    "| Column name | data type | description |\n",
    "| ----------- | --------- | ------------------------------- |\n",
    "| **cicid**       | **FLOAT**       | **immigration record id**      |\n",
    "| i94yr       | INT       | year of immigration record      |\n",
    "| i94mon      | INT       | month of immigration record      |\n",
    "| i94cit      | VARCHAR(3)| origin country code               |\n",
    "| i94port     | CHAR(3)   | US city code of arrival port      |\n",
    "| arrdate     | FLOAT     | arrival date at US port in sas date format      |\n",
    "| depdate     | FLOAT     | departure date from US in sas date format      |\n",
    "| i94visa     | FLOAT     | reason for visit      |\n",
    "| dt       | VARCHAR(256)       | month of temperature record in yyyy-mm-dd     |\n",
    "| AverageTemperature      | FLOAT       | average temperature for recorded month      |\n",
    "| City      | VARCHAR(256)| city of temperature record               |\n",
    "| Country     | VARCHAR(256)   | country of temperature record      |\n",
    "| Latitude     | VARCHAR(256)     | latitude      |\n",
    "| Longitude     | VARCHAR(256)     | longitude       |\n",
    "\n",
    "These columns were chosen based on the fact that a user of the optimized fact table wants to easily see the average temperature of the month of the port of arrival. The more detailed columns from the immigration table do not enrich the use case for which the fact table is being built. \\\n",
    "The immigration records are enriched with temperature data for the port of arrival. Each record remains unique through the **cicid** column. The fact table can be seen as a transaction table, new visits to the US are recorded and appended to the table. Existing records do not change. \n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "1. Start SparkSession\n",
    "2. Ingest the data into Spark (immigration) and pandas (temperature) dataframes\n",
    "3. Extract cities and i94_ports dictionairies from I94_SAS_labels\n",
    "4. Clean the temperature data with dedicated cleaning function (see clean_temperature function for specifics)\n",
    "5. Clean immigration data with dedicated function (see clean_immigration for specifics)\n",
    "6. Run data quality checks on completeness of ingested data\n",
    "7. Write cleaned and checked tables (immigration and temperature) to standardized storage as parquet files\n",
    "8. Combine standardized spark tables to a single optimized fact table to be updated regularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check function to determine if standardized datasets contain data and if there are null values\n",
    "def check_data_quality(df, string_of_df_to_check, exclude_cols=[]):\n",
    "    \"\"\"\n",
    "    Performs data quality checks on a Spark DataFrame. Checks if there are columns that contain null/Nan values.\n",
    "    Takes as inputs a Spark DataFrame, a string variable of the name of the DataFrame to check, \n",
    "    and an optional list of columns to exclude from the null/Nan values check in case there are expected null/Nan values.\n",
    "    Returns True if the DataFrame contains data and has no null/Nan values, and prints an error otherwise.\n",
    "    \"\"\"\n",
    "    if df.count() == 0:\n",
    "        raise ValueError (f\"Error: DataFrame {string_of_df_to_check} is empty\")\n",
    "        \n",
    "    else:\n",
    "        null_columns = []\n",
    "        for c in df.columns:\n",
    "            if c in exclude_cols:\n",
    "                continue\n",
    "            null_count = df.filter((isnan(c) | df[c].isNull())).count()\n",
    "            if null_count > 0:\n",
    "                null_columns.append(c)\n",
    "        if null_columns:\n",
    "            print(f\"Error: DataFrame {string_of_df_to_check} contains null/Nan values in columns: {null_columns}\")\n",
    "        else:\n",
    "            print(f\"Data quality checks passed: DataFrame {string_of_df_to_check} contains data and has no null/Nan values\")\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df):\n",
    "    \"\"\"\n",
    "    Checks a Spark DataFrame for duplicate records.\n",
    "    Returns True if the DataFrame contains no duplicate records, and False otherwise.\n",
    "    \"\"\"\n",
    "    count_before = df.count()\n",
    "    df = df.dropDuplicates()\n",
    "    count_after = df.count()\n",
    "    if count_before == count_after:\n",
    "        print(\"No duplicate records found\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Error: {count_before - count_after} duplicate records found\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "spark.conf.set(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Ingest data\n",
    "## immigration dataset\n",
    "df_imm = spark.read.parquet(\"sas_data\")\n",
    "## temperature dataset\n",
    "tempa_file_name = \"GlobalLandTemperaturesByCity.csv\"\n",
    "tempa = pd.read_csv(tempa_file_name, sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Extract cities and i94_ports dictionairies from I94_SAS_Labels\n",
    "regex_pattern = re.compile(r\"\\'(.*)\\'.*\\'([A-Z\\-a-z]+)(.*)\\'\")\n",
    "i94_ports = {}\n",
    "cities = {}\n",
    "with open(\"I94_SAS_Labels_Descriptions.sas\") as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines[303:962]:\n",
    "    match = regex_pattern.search(line)\n",
    "    i94_ports[match[1]] = match[2]\n",
    "    cities[match[2].title()] = match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terminator/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/Users/terminator/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+-------------+--------+---------+-------+\n",
      "|dt        |AverageTemperature|City       |Country      |Latitude|Longitude|i94port|\n",
      "+----------+------------------+-----------+-------------+--------+---------+-------+\n",
      "|2012-04-01|9.195             |Akron      |United States|40.99N  |80.95W   |CAK    |\n",
      "|2012-04-01|13.133            |Albuquerque|United States|34.56N  |107.03W  |ABQ    |\n",
      "|2012-04-01|12.158            |Alexandria |United States|39.38N  |76.99W   |AXB    |\n",
      "|2012-04-01|0.4289999999999998|Anchorage  |United States|61.88N  |151.13W  |ANC    |\n",
      "|2012-04-01|16.287            |Atlanta    |United States|34.56N  |83.68W   |ATL    |\n",
      "|2012-04-01|22.44100000000001 |Austin     |United States|29.74N  |97.85W   |AUS    |\n",
      "|2012-04-01|12.158            |Baltimore  |United States|39.38N  |76.99W   |BAL    |\n",
      "|2012-04-01|22.031            |Beaumont   |United States|29.74N  |94.15W   |BEA    |\n",
      "|2012-04-01|18.724            |Birmingham |United States|32.95N  |87.13W   |BHX    |\n",
      "|2012-04-01|8.753             |Boston     |United States|42.59N  |72.00W   |BOS    |\n",
      "+----------+------------------+-----------+-------------+--------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Clean temperature data\n",
    "tempa_table = clean_temperature(tempa, cities)\n",
    "tempa_table.show(truncate=False, n=10)\n",
    "tempa_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+-------+-------+-------+-------+\n",
      "|cicid    |i94yr |i94mon|i94cit|i94port|arrdate|depdate|i94visa|\n",
      "+---------+------+------+------+-------+-------+-------+-------+\n",
      "|5748517.0|2016.0|4.0   |245.0 |LOS    |20574.0|20582.0|1.0    |\n",
      "|5748518.0|2016.0|4.0   |245.0 |LOS    |20574.0|20591.0|1.0    |\n",
      "|5748519.0|2016.0|4.0   |245.0 |LOS    |20574.0|20582.0|1.0    |\n",
      "|5748520.0|2016.0|4.0   |245.0 |LOS    |20574.0|20588.0|1.0    |\n",
      "|5748521.0|2016.0|4.0   |245.0 |LOS    |20574.0|20588.0|1.0    |\n",
      "|5748522.0|2016.0|4.0   |245.0 |HHW    |20574.0|20579.0|2.0    |\n",
      "|5748523.0|2016.0|4.0   |245.0 |HHW    |20574.0|20586.0|2.0    |\n",
      "|5748524.0|2016.0|4.0   |245.0 |HHW    |20574.0|20586.0|2.0    |\n",
      "|5748525.0|2016.0|4.0   |245.0 |HOU    |20574.0|20581.0|2.0    |\n",
      "|5748526.0|2016.0|4.0   |245.0 |LOS    |20574.0|20581.0|2.0    |\n",
      "+---------+------+------+------+-------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096242"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Clean immigration data\n",
    "imm_table = clean_immigration(df_imm, i94_ports)\n",
    "imm_table.show(truncate=False, n=10)\n",
    "imm_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality checks passed: DataFrame temperature table contains data and has no null/Nan values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Run data quality checks\n",
    "check_data_quality(tempa_table, \"temperature table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate records found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_duplicates(tempa_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality checks passed: DataFrame immigration table contains data and has no null/Nan values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data_quality(imm_table, \"immigration table\", [\"depdate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:>                                                       (0 + 16) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate records found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_duplicates(imm_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 7. Write cleaned and checked tables (immigration and temperature) to standardized storage as parquet files \n",
    "tempa_table.coalesce(1).write.mode(\"overwrite\").parquet(\"./standardized/temperature_standardized\")\n",
    "imm_table.coalesce(1).write.mode(\"overwrite\").parquet(\"./standardized/immigration_standardized\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we are currently using \"overwrite\" mode and writing out to a single file with coalesce. This is because the dataset is not large yet and parquet file sizes are optimized for file size between 512MB and 1GB (or an HDFS block). Many small file sizes actually reduce the reading time of the dataset and could also result in higher costs caused by the way in which spark executes compute on its nodes. \\\n",
    "We are overwriting as there is currently no new data coming in and we are still in the development stage. Once the solution goes to production with regular updates the mode will be changed to \"append\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096797"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Combine standardized immigration and temperature tables using a left join on immigration table on i94_port\n",
    "imm_fact_table = imm_table.join(tempa_table, on = \"i94port\", how = \"left\")\n",
    "imm_fact_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+--------------------+-------+------------------+-----------------+------------------+------------------+----------+------------------+-----------+-------------+--------+---------+\n",
      "|summary|i94port|             cicid|               i94yr| i94mon|            i94cit|          arrdate|           depdate|           i94visa|        dt|AverageTemperature|       City|      Country|Latitude|Longitude|\n",
      "+-------+-------+------------------+--------------------+-------+------------------+-----------------+------------------+------------------+----------+------------------+-----------+-------------+--------+---------+\n",
      "|  count|3096797|           3096797|             3096797|3096797|           3096797|          3096797|           2954310|           3096797|   1389943|           1389943|    1389943|      1389943| 1389943|  1389943|\n",
      "|   mean|   null| 3078504.781015998|              2016.0|    4.0|304.91112849825157|20559.84772686101|20573.952449133638|1.8453980031626225|      null|16.972176259022568|       null|         null|    null|     null|\n",
      "| stddev|   null|1763321.0851299735|1.990988405191755...|    0.0|210.02745821903707|8.777417748040724| 29.35631447766339|0.3983905403984622|      null| 6.320254757343178|       null|         null|    null|     null|\n",
      "|    min|    5KE|               6.0|              2016.0|    4.0|             101.0|          20545.0|           15176.0|               1.0|2012-04-01|0.4289999999999998|Albuquerque|United States|  26.52N|  104.05W|\n",
      "|    25%|   null|         1577283.0|              2016.0|    4.0|             135.0|          20552.0|           20561.0|               2.0|      null|10.324000000000002|       null|         null|    null|     null|\n",
      "|    50%|   null|         3103218.0|              2016.0|    4.0|             213.0|          20560.0|           20570.0|               2.0|      null|            20.552|       null|         null|    null|     null|\n",
      "|    75%|   null|         4654304.0|              2016.0|    4.0|             512.0|          20567.0|           20579.0|               2.0|      null|            22.977|       null|         null|    null|     null|\n",
      "|    max|    YSL|         6102785.0|              2016.0|    4.0|             999.0|          20574.0|           45427.0|               3.0|2012-04-01|            24.985| Washington|United States|  61.88N|   99.09W|\n",
      "+-------+-------+------------------+--------------------+-------+------------------+-----------------+------------------+------------------+----------+------------------+-----------+-------------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "imm_fact_table.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "imm_fact_table.coalesce(1).write.mode(\"overwrite\").parquet(\"./optimized/optimized_immigration_fact\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "\n",
    "##### Creating value through Agile development\n",
    "The Capstone project provides potential end-users (immigration officers, travel agencies, government officials, social sciences researchers, ESG reporting companies) with a fact table that links temperatures of ports of arrival in the US with influx of US aliens. The purpose of the project is to stay true to agile development and quickly deliver a preliminary solution to users to determine if more value can be generated. To that effect the notebook can be executed on a local machine provided that the input datasets have been downloaded from the repository. The functions and pipeline have however been set up to be efficient and to easily scale with little amendment. As it stands the data should be updated yearly with new data. \\\n",
    "The data model as defined in 3.1 together with the pipeline undergoes a robust and scalable data protocol: raw -> standardized -> optimized. In a following iteration the fact table would reside and be updated in an enriched stage upon which several different optimized tables flow from. \\\n",
    "A data dictionary can also be found in 3.1 with descriptions of the columns. \n",
    "##### Limitations\n",
    "The current setup has several limitations as discussed throughout the notebook. Mainly the completeness of the datasets and the availability of data across years poses issues. \\\n",
    "To improve the standardized tables and optimized fact table more reliable datasets could be found that can schedule updates directly from the API of which they originate. This would also allow the introduction of Airflow to schedule and orchestrate updates. \n",
    "##### Performance\n",
    "The standardized tables and optimized table are currently stored locally in parquet files using spark tables. For the several million records currently ingested and in the output this runs very efficiently. Once the solution needs to scale to multiple years of temperature and immigration data a next step would be to containerize the solution in Docker and provide enough compute power for regular updates. The data would also be partitioned on i94_ports and by year/month for organised access. \\\n",
    "A step after this would be to create a virtual machine (VM) with enough storage to hold many years. This will work efficiently for up to a 100 users if the storage disk is large enough, say 128GB, and if the core count is at least 32. With this setup even a large fact table with many concurrent read operations will suffice a 100 users. \\\n",
    "However, once the optimized dataset becomes larger with more countries, more historic years, more frequent (say monthly) updates, and over 100 users the solution will need to be scaled to the Cloud. The VM setup can still provide the compute power for updates and ingestion, but the storage will need to be handled by a data lake preferably. The optimized table can be migrated to a dedicated Redshift cluster upon which unlimited users will be able to execute read operations for downstream analysis, such as dashboarding or reports. \n",
    "##### Scaling\n",
    "The fully scaled solution (Large datasets, 100+ people, and daily updates) would look something like this:\n",
    "- Ingest the immigration \"transaction\" data daily upon availability using Airflow and EMR cluster (self-maintained and optimized for Airflow and raw data API origins as well as its network and data centre locations).\n",
    "- Store the raw immigration data in S3. \n",
    "- Update the standardized tables through event-driven scheduling on arrival of raw daily immigration data in S3 raw using EC2 (managed Spark) and orchestrate with Airflow.\n",
    "- Update enriched stage table in dedicated Redshift cluster. \n",
    "- Update various optimized tables in the Redshift cluster to be served to end-users through dashboarding tools, semantic/output layer tools such as dbt, Supergrain, Hex. Ensure that data monitoring checks are in place before updating the optimized tables to ensure constant uptime. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "10369f38e51abe3fa962664b6fad7aab9c49b25901eeb4ef9b49a844b27c7489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
